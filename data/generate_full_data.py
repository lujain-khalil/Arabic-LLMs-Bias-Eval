# -*- coding: utf-8 -*-
"""Generate Full Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QbGOyfnHUPLMmwYQRyzLrDAGPs5M-NKw
"""

import numpy as np
import pandas as pd

file_path = "/content/drive/MyDrive/Data Mining Project/New Data/sentiment_words.csv"
data = pd.read_csv(file_path)

data.head()

data = data.drop_duplicates()

positive_samples = data[data['sentiment'] == 'positive'].sample(n=80, random_state=42)
negative_samples = data[data['sentiment'] == 'negative'].sample(n=80, random_state=42)

sampled_data = pd.concat([positive_samples, negative_samples])

output_path = '/content/drive/MyDrive/Data Mining Project/New Data/processed_sentiment_terms.csv'
sampled_data.to_csv(output_path, index=False)

print(f"Sampled data saved to {output_path}")

file_path = "/content/drive/MyDrive/Data Mining Project/New Data/culture_terms.csv"

data = pd.read_csv(file_path)

data.head(), data.info()

data = data.drop_duplicates()
data.info()

def sample_terms(group):
    if len(group) < 10:
        return group
    return group.sample(n=20, random_state=42)

sampled_data = data.groupby(['culture', 'entity'], group_keys=False).apply(sample_terms)

total_terms = sampled_data.shape[0]

print(f"Total terms sampled: {total_terms}")
if total_terms < 400:
    print("Not all groups had enough terms to sample from. The dataset will contain fewer than 400 terms.")

output_path = "/content/drive/MyDrive/Data Mining Project/New Data/processed_culture_terms.csv"
sampled_data.to_csv(output_path, index=False)

print(f"Sampled data saved to {output_path}")

file_path = '/content/drive/MyDrive/Data Mining Project/New Data/camelag-prompts-masked-lms (3).xlsx'
data = pd.read_excel(file_path)

data.head(), data.info()

data = data.drop_duplicates()

def sample_per_entity(group):
    return group.sample(n=5, random_state=42) if len(group) >= 5 else group

sampled_data = data.groupby('Entity Type', group_keys=False).apply(sample_per_entity)

output_path = '/content/drive/MyDrive/Data Mining Project/New Data/step1-processed-camelag-prompts-masked-lms.xlsx'
sampled_data.to_excel(output_path, index=False)

print(f"Sampled data saved to {output_path}")

step1_file_path = '/content/drive/MyDrive/Data Mining Project/New Data/step1-processed-camelag-prompts-masked-lms.xlsx'
terms_file_path = '/content/drive/MyDrive/Data Mining Project/New Data/processed_culture_terms.csv'

step1_data = pd.read_excel(step1_file_path)
terms_data = pd.read_csv(terms_file_path)

step1_data['Entity Type'] = step1_data['Entity Type'].str.strip().str.lower()
terms_data['entity'] = terms_data['entity'].str.strip().str.lower()

step1_data['Entity Type'] = step1_data['Entity Type'].replace('location', 'locations')

terms_data['entity'] = terms_data['entity'].replace('sports clubs', 'sports clubs')

terms_data = terms_data.rename(columns = {"entity" : "Entity Type"})

step1_data['Entity Type'].value_counts()

terms_data['Entity Type'].value_counts()

missing_entities = set(step1_data['Entity Type'].unique()) - set(terms_data['Entity Type'].unique())
if missing_entities:
    print(f"Warning: The following Entity Types are missing in terms data: {missing_entities}")

step1_data.head(), step1_data.info(), terms_data.head(), terms_data.info()

result = []

for entity_type in step1_data['Entity Type'].unique():
    prompts = step1_data[step1_data['Entity Type'] == entity_type]
    terms = terms_data[terms_data['Entity Type'] == entity_type]

    for _, prompt_row in prompts.iterrows():
        for _, term_row in terms.iterrows():
            processed_prompt = prompt_row["Prompt"].replace("[MASK]", term_row["term"])
            result.append({
                "Entity Type": entity_type,
                "Original Prompt": prompt_row["Prompt"],
                "Processed Prompt": processed_prompt,
                "Sentiment": prompt_row["Sentiment"],
                "culture": term_row["culture"],
                "term": term_row["term"]
            })

result_df = pd.DataFrame(result)

output_path = '/content/drive/MyDrive/Data Mining Project/New Data/prompts.csv'
result_df.to_csv(output_path, index=False)

print(f"Generated sentences saved to {output_path}")

