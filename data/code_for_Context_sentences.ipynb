{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Umjh8aVRsj65",
        "outputId": "a4cfb19f-7988-4a76-e556-dddd3b5bcbbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts for Arab Culture:\n",
            "  Culture            Entity  Count\n",
            "0    Arab           Authors    206\n",
            "1    Arab         Beverage      54\n",
            "2    Arab   Clothing-Female     23\n",
            "3    Arab     Clothing-Male     23\n",
            "4    Arab              Food    252\n",
            "5    Arab         Locations   1061\n",
            "6    Arab      Names-Female    424\n",
            "7    Arab        Names-Male    232\n",
            "8    Arab  Religious Places    900\n",
            "9    Arab      Sports Clubs   1230\n",
            "\n",
            "Counts for Western Culture:\n",
            "    Culture            Entity  Count\n",
            "10  Western           Authors    206\n",
            "11  Western         Beverage      54\n",
            "12  Western   Clothing-Female     23\n",
            "13  Western     Clothing-Male     23\n",
            "14  Western              Food    252\n",
            "15  Western         Locations   1061\n",
            "16  Western      Names-Female    424\n",
            "17  Western        Names-Male    232\n",
            "18  Western  Religious Places    900\n",
            "19  Western      Sports clubs   1230\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "# Replace 'file_path.csv' with the actual path to your file\n",
        "file_path = 'culture_terms.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Group by Culture and Entity, then count the occurrences\n",
        "entity_counts = data.groupby(['Culture', 'Entity']).size().reset_index(name='Count')\n",
        "\n",
        "\n",
        "# Separate the counts for Arab and Western cultures\n",
        "arab_counts = entity_counts[entity_counts['Culture'] == 'Arab']\n",
        "western_counts = entity_counts[entity_counts['Culture'] == 'Western']\n",
        "\n",
        "# Display the results\n",
        "print(\"Counts for Arab Culture:\")\n",
        "print(arab_counts)\n",
        "print(\"\\nCounts for Western Culture:\")\n",
        "print(western_counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the files with proper encoding\n",
        "sentences_file = '/content/camelag-prompts-causal-lms.xlsx'  # Replace with your actual file path\n",
        "entities_file = '/content/culture_terms.csv'    # Replace with your actual file path\n",
        "\n",
        "# Load data with encoding for Arabic text\n",
        "sentences_df = pd.read_excel(sentences_file)  # For .xlsx file\n",
        "entities_df = pd.read_csv(entities_file, encoding='utf-8')  # For .csv file\n",
        "\n",
        "# Generate replacements\n",
        "replacements = []\n",
        "\n",
        "for _, sentence_row in sentences_df.iterrows():\n",
        "    prompt = sentence_row[\"Prompt\"]\n",
        "    entity_type = sentence_row[\"Entity Type\"]\n",
        "\n",
        "    # Find all matching entities for the entity type\n",
        "    matching_entities = entities_df[entities_df[\"Entity\"] == entity_type]\n",
        "\n",
        "    for _, entity_row in matching_entities.iterrows():\n",
        "        culture = entity_row[\"Culture\"]\n",
        "        term = entity_row[\"Term\"]\n",
        "\n",
        "        # Replace [MASK] in the sentence with the term\n",
        "        replaced_sentence = prompt.replace(\"[MASK]\", term)\n",
        "\n",
        "        # Append the result\n",
        "        replacements.append({\n",
        "            \"Entity\": entity_type,\n",
        "            \"Culture\": culture,\n",
        "            \"Sentence\": replaced_sentence,\n",
        "        })\n",
        "\n",
        "# Convert replacements to a DataFrame\n",
        "replaced_sentences_df = pd.DataFrame(replacements)\n",
        "\n",
        "# Save the output to a CSV file with proper encoding for Arabic\n",
        "output_file = 'context_sentences.csv'\n",
        "replaced_sentences_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"Replaced sentences saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7HA9YXzzhjc",
        "outputId": "f0c16b92-bccc-4fdd-d73b-6cc8659c9d78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replaced sentences saved to context_sentences.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UurwT-KS0Feq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}